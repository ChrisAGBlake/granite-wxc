{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4548c3cc-7537-4d14-8d3e-c703e08098df",
   "metadata": {},
   "source": [
    "# Prithvi WxC Downscaling: Model Inference\n",
    "\n",
    "This notebook is a walk through to use a finetuned downscaling model to generate inferences. We show how to initalize the model, load weights, and use the model for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd0463-3a0c-4cf0-8ba7-748327411e65",
   "metadata": {},
   "source": [
    "*Note to set up env run these commands in your terminal before running the notebook*\n",
    "- `conda create -n prithviwxc python=3.11 h5netcdf matplotlib wget pyyaml xarray scipy`\n",
    "- `conda activate prithviwxc`\n",
    "- `pip install -e <path to cloned PrithviWxC repo>` (see https://github.com/NASA-IMPACT/Prithvi-WxC)\n",
    "- `pip install -e <path to cloned granite-wxc repo>` (see https://github.com/IBM/granite-wxc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf141b3-6577-4846-9793-a1db11edbd2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T19:57:48.680880Z",
     "iopub.status.busy": "2024-09-20T19:57:48.680564Z",
     "iopub.status.idle": "2024-09-20T19:57:48.740394Z",
     "shell.execute_reply": "2024-09-20T19:57:48.739891Z",
     "shell.execute_reply.started": "2024-09-20T19:57:48.680854Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from granitewxc.utils.config import get_config\n",
    "from granitewxc.utils.data import _get_transforms\n",
    "from granitewxc.datasets.merra2 import Merra2DownscaleDataset\n",
    "from granitewxc.utils.downscaling_model import get_finetune_model\n",
    "from PrithviWxC.dataloaders.merra2 import SampleSpec\n",
    "\n",
    "from examples.granitewxc_downscaling.utils.plot import *\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c34161",
   "metadata": {},
   "source": [
    "Configure the backends and torch states, including setting the seeds for the RNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eaba0e-9a11-4c54-bb61-f9e5350dda09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T18:30:34.397306Z",
     "iopub.status.busy": "2024-09-20T18:30:34.396814Z",
     "iopub.status.idle": "2024-09-20T18:30:34.817974Z",
     "shell.execute_reply": "2024-09-20T18:30:34.817220Z",
     "shell.execute_reply.started": "2024-09-20T18:30:34.397276Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.jit.enable_onednn_fusion(True)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05238888",
   "metadata": {},
   "source": [
    "It is possible to use a cpu or gpu/s to generate inferences. Based on avaiablity of a cuda:gpu we set the device the model uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deaa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c2b66f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa74b62",
   "metadata": {},
   "source": [
    "We provide a configuration file that is used to configure data variables and model parameters. For inference most of these configurations are used as is. This includes the variables that the model is trained on, the variables that we downscale, the number of input timesteps, the amount of downscaling, the embedding dimensions for the model. When necessary, we will show which configurations need to be specified or changed outside of what is set in this file already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe9d7f-ebe4-4669-ad9f-58f1a3664a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T18:30:35.042683Z",
     "iopub.status.busy": "2024-09-20T18:30:35.042185Z",
     "iopub.status.idle": "2024-09-20T18:30:35.145250Z",
     "shell.execute_reply": "2024-09-20T18:30:35.144820Z",
     "shell.execute_reply.started": "2024-09-20T18:30:35.042652Z"
    }
   },
   "outputs": [],
   "source": [
    "config_path = '../configs/inference_config.yaml'\n",
    "config = get_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd31812",
   "metadata": {},
   "source": [
    "### Download Model and Sample Data\n",
    "\n",
    "We provide sample data from MERRA-2 dataset for a single day (2020 January 01), and [weights](https://huggingface.co/ibm-granite/granite-geospatial-wxc-downscaling/tree/main) for a finetuned downscaling model that we use in this notebook. These will be downloaded when you run the cell/s below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e751323",
   "metadata": {},
   "source": [
    "Before running the download set `config.download_path` to the directory where you want the model and sample data to be downloaded\n",
    "\n",
    "*Note*: With `config.download_path = './'` the files are downloaded in the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58033654",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.download_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget.download('https://huggingface.co/ibm-granite/granite-geospatial-wxc-downscaling/resolve/main/granite.wxc.2300m.v1.downscaling.v1.pth', out=config.download_path)\n",
    "os.makedirs(os.path.join(config.download_path, 'climatology'), exist_ok=True)\n",
    "os.makedirs(os.path.join(config.download_path, 'merra-2'), exist_ok=True)\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/merra-2/MERRA2_sfc_20200101.nc', out=os.path.join(config.download_path, 'merra-2', 'MERRA2_sfc_20200101.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/merra-2/MERRA_pres_20200101.nc', out=os.path.join(config.download_path, 'merra-2', 'MERRA_pres_20200101.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/anomaly_variance_surface.nc', out=os.path.join(config.download_path, 'climatology', 'anomaly_variance_surface.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/anomaly_variance_vertical.nc', out=os.path.join(config.download_path, 'climatology', 'anomaly_variance_vertical.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/musigma_surface.nc', out=os.path.join(config.download_path, 'climatology', 'musigma_surface.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/musigma_vertical.nc', out=os.path.join(config.download_path, 'climatology', 'musigma_vertical.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_surface_doy001_hour00.nc', out=os.path.join(config.download_path, 'climatology', 'climate_surface_doy001_hour00.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_surface_doy001_hour03.nc', out=os.path.join(config.download_path, 'climatology', 'climate_surface_doy001_hour03.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_surface_doy001_hour06.nc', out=os.path.join(config.download_path, 'climatology', 'climate_surface_doy001_hour06.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_surface_doy001_hour09.nc', out=os.path.join(config.download_path, 'climatology', 'climate_surface_doy001_hour09.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_surface_doy001_hour12.nc', out=os.path.join(config.download_path, 'climatology', 'climate_surface_doy001_hour12.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_surface_doy001_hour15.nc', out=os.path.join(config.download_path, 'climatology', 'climate_surface_doy001_hour15.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_surface_doy001_hour18.nc', out=os.path.join(config.download_path, 'climatology', 'climate_surface_doy001_hour18.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_surface_doy001_hour21.nc', out=os.path.join(config.download_path, 'climatology', 'climate_surface_doy001_hour21.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_vertical_doy001_hour00.nc', out=os.path.join(config.download_path, 'climatology', 'climate_vertical_doy001_hour00.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_vertical_doy001_hour03.nc', out=os.path.join(config.download_path, 'climatology', 'climate_vertical_doy001_hour03.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_vertical_doy001_hour06.nc', out=os.path.join(config.download_path, 'climatology', 'climate_vertical_doy001_hour06.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_vertical_doy001_hour09.nc', out=os.path.join(config.download_path, 'climatology', 'climate_vertical_doy001_hour09.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_vertical_doy001_hour12.nc', out=os.path.join(config.download_path, 'climatology', 'climate_vertical_doy001_hour12.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_vertical_doy001_hour15.nc', out=os.path.join(config.download_path, 'climatology', 'climate_vertical_doy001_hour15.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_vertical_doy001_hour18.nc', out=os.path.join(config.download_path, 'climatology', 'climate_vertical_doy001_hour18.nc'))\n",
    "wget.download('https://huggingface.co/Prithvi-WxC/prithvi.wxc.2300m.v1/resolve/main/climatology/climate_vertical_doy001_hour21.nc', out=os.path.join(config.download_path, 'climatology', 'climate_vertical_doy001_hour21.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c50d5",
   "metadata": {},
   "source": [
    "Based on the path to the sample data downloaded in the above cells we specify the paths that are required by the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data.data_path_surface = os.path.join(config.download_path,'merra-2')\n",
    "config.data.data_path_vertical = os.path.join(config.download_path, 'merra-2')\n",
    "config.data.climatology_path_surface = os.path.join(config.download_path,'climatology')\n",
    "config.data.climatology_path_vertical = os.path.join(config.download_path,'climatology')\n",
    "\n",
    "config.model.input_scalers_surface_path = os.path.join(config.download_path,'climatology/musigma_surface.nc')\n",
    "config.model.input_scalers_vertical_path = os.path.join(config.download_path,'climatology/musigma_vertical.nc')\n",
    "config.model.output_scalers_surface_path = os.path.join(config.download_path,'climatology/anomaly_variance_surface.nc')\n",
    "config.model.output_scalers_vertical_path = os.path.join(config.download_path,'climatology/anomaly_variance_vertical.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24860c-bc0f-4cf6-84e7-a4ac9f4221a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataloader\n",
    "\n",
    "With the environment ready to go, we now need to set up the task. The core model expects a fixed set of variables from the MERRA-2 dataset, which are defined in the configuration file. The variables are comprised of surface variables, surface static variables, and variables at various vertical levels within the atmosphere. More details on the MERRA-2 dataset can be found [here](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/).\n",
    "\n",
    "The task of the model is, given the input data, to increase the resolution of 2m surface temperature by 6x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59887ecc",
   "metadata": {},
   "source": [
    "Set the range of the data to the sample data that we downloaded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data.val_time_range_start = '2020-01-01T00:00:00'\n",
    "config.data.val_time_range_end = '2020-01-01T23:59:59'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d2237",
   "metadata": {},
   "source": [
    "Initialize `Merra2DownscaleDataset` class. \n",
    "\n",
    "This class is used to create samples as expected by the downscaling model. Using the transforms specified in the dataset class we coarsen and smoothen the MERRA-2 data to use as a low-resolution input to out model. The original data is used as the corresponding high-resolution data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873ef0c-7bcb-494b-9963-bd64b56f9d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T18:30:35.200325Z",
     "iopub.status.busy": "2024-09-20T18:30:35.200149Z",
     "iopub.status.idle": "2024-09-20T18:30:36.386899Z",
     "shell.execute_reply": "2024-09-20T18:30:36.386377Z",
     "shell.execute_reply.started": "2024-09-20T18:30:35.200310Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Merra2DownscaleDataset(\n",
    "    time_range=(config.data.val_time_range_start, config.data.val_time_range_end),\n",
    "    data_path_surface = config.data.data_path_surface,\n",
    "    data_path_vertical = config.data.data_path_vertical,\n",
    "    climatology_path_surface = config.data.climatology_path_surface,\n",
    "    climatology_path_vertical = config.data.climatology_path_vertical,\n",
    "    input_surface_vars = config.data.input_surface_vars,\n",
    "    input_static_surface_vars = config.data.input_static_surface_vars,\n",
    "    input_vertical_vars = config.data.input_vertical_vars,\n",
    "    input_levels = config.data.input_levels,\n",
    "    n_input_timestamps = config.data.n_input_timestamps,\n",
    "    output_vars=config.data.output_vars,\n",
    "    transforms=_get_transforms(config),\n",
    ")\n",
    "\n",
    "assert len(dataset) > 0, \"There doesn't seem to be any valid data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5475fe",
   "metadata": {},
   "source": [
    "### Model Init\n",
    "\n",
    "We build the model using the loaded configuration. To use the model for inference with the provided weights we will keep the model configuration the same as defined in the configuration file\n",
    "\n",
    "\n",
    "The graintewxc downscale model consists of a patch embedding layer, followed by an upscaling layer that increases the resolution by 2x, then we use the pre-trained encoder of the PrithviWxC model followed by another upscaling operation that increases the resolution by 3x for a total of 6x resolution gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_finetune_model(config, logger=None)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f2b74-f923-4bc7-81f1-9dcac83df827",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load weights\n",
    "\n",
    "We can now load the weights we downloaded earlier the model that we initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fd455-5e7d-4779-ad7a-c3f679d7de28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T18:32:34.583497Z",
     "iopub.status.busy": "2024-09-20T18:32:34.582963Z",
     "iopub.status.idle": "2024-09-20T18:32:59.237500Z",
     "shell.execute_reply": "2024-09-20T18:32:59.236617Z",
     "shell.execute_reply.started": "2024-09-20T18:32:34.583476Z"
    }
   },
   "outputs": [],
   "source": [
    "weights_path = Path(config.download_path,'granite.wxc.2300m.v1.downscaling.v1.pth')\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(weights_path, weights_only=False, map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5834fb-31df-4732-a926-bb1376b9ad42",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference\n",
    "\n",
    "The model is now ready for inference. We are running an inference for only one sample, but you can add a loop to run the inference for multiple samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d3e93-736a-4209-b34c-f32ae1b32eaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T18:33:13.776977Z",
     "iopub.status.busy": "2024-09-20T18:33:13.776380Z",
     "iopub.status.idle": "2024-09-20T18:33:45.505968Z",
     "shell.execute_reply": "2024-09-20T18:33:45.505365Z",
     "shell.execute_reply.started": "2024-09-20T18:33:13.776949Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    batch = next(iter(dataloader))\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    out = model(batch)\n",
    "        \n",
    "    inputs = batch['x']\n",
    "    targets = batch['y']\n",
    "    outputs = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f084d8-6072-47ff-8276-e4573232044f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T18:33:45.507067Z",
     "iopub.status.busy": "2024-09-20T18:33:45.506887Z",
     "iopub.status.idle": "2024-09-20T18:33:45.568754Z",
     "shell.execute_reply": "2024-09-20T18:33:45.568317Z",
     "shell.execute_reply.started": "2024-09-20T18:33:45.507050Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs.shape, targets.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0a99e-3014-4f0d-b10d-b6f90572d5ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd886d8",
   "metadata": {},
   "source": [
    "We set the variable names and description and extract the sample information for generating plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ca62c-ce10-4390-88b9-5c1df864a68c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T19:59:22.286831Z",
     "iopub.status.busy": "2024-09-20T19:59:22.286491Z",
     "iopub.status.idle": "2024-09-20T19:59:22.348934Z",
     "shell.execute_reply": "2024-09-20T19:59:22.348334Z",
     "shell.execute_reply.started": "2024-09-20T19:59:22.286808Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "var_name = \"T2M\"\n",
    "var_name_title = '2M air temperature'\n",
    "var_unit = \"K\"\n",
    "\n",
    "input_vars = [*config.data.input_surface_vars, *product(config.data.input_vertical_vars, config.data.input_levels)]\n",
    "input_t2m_index= input_vars.index(var_name)\n",
    "\n",
    "sample_idx = 0\n",
    "coarsening_factor = targets.shape[-1] / inputs.shape[-1]\n",
    "sample_timestamp, sample_it, sample_lt = dataset.dataset.samples[sample_idx][0]\n",
    "sample_time_spec = SampleSpec.get(sample_timestamp, -sample_it, sample_lt)\n",
    "sample_time = sample_time_spec.inputs[-1]\n",
    "\n",
    "f'{var_name_title} at {sample_time} is downscaled by {coarsening_factor}x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a05bf4-d784-4aa6-aa7e-9e36ced47b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T19:38:47.091065Z",
     "iopub.status.busy": "2024-09-20T19:38:47.090817Z",
     "iopub.status.idle": "2024-09-20T19:38:47.168015Z",
     "shell.execute_reply": "2024-09-20T19:38:47.167526Z",
     "shell.execute_reply.started": "2024-09-20T19:38:47.091046Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_input = inputs[0, input_t2m_index, :, :].detach().cpu().numpy()\n",
    "plot_target = targets[0, 0, : ,:].detach().cpu().numpy()\n",
    "plot_output = outputs[0, 0, :, :].detach().cpu().numpy()\n",
    "plot_residual = plot_target - plot_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4ed9f-fdaa-4fbc-a515-28da25afc4f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T20:02:06.064478Z",
     "iopub.status.busy": "2024-09-20T20:02:06.064243Z",
     "iopub.status.idle": "2024-09-20T20:02:06.533952Z",
     "shell.execute_reply": "2024-09-20T20:02:06.533392Z",
     "shell.execute_reply.started": "2024-09-20T20:02:06.064462Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_val_kwargs = dict(\n",
    "    cmap='RdYlBu_r',\n",
    "    vmin = min(np.min(plot_input), np.min(plot_target), np.min(plot_output)),\n",
    "    vmax = max(np.max(plot_input), np.max(plot_target), np.max(plot_output)),\n",
    "    plot_residual_kwargs = dict(\n",
    "        cmap = 'bwr',\n",
    "        vmin = -np.max(np.abs(plot_residual)),\n",
    "        vamx = np.max(np.abs(plot_residual)),\n",
    "    ),\n",
    "    var_name_title=var_name_title,\n",
    "    var_unit=var_unit\n",
    ")\n",
    "\n",
    "plot_model_results(\n",
    "    [plot_input, plot_output, plot_target],\n",
    "    ['Input', 'AI Model', 'Ground truth'],\n",
    "    title=f\"Downscaling '{var_name_title}' at {sample_time} by {coarsening_factor}x\",\n",
    "    **plot_val_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42774052-9f8b-4415-ac8f-207902a5ea7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T20:03:55.224670Z",
     "iopub.status.busy": "2024-09-20T20:03:55.224359Z",
     "iopub.status.idle": "2024-09-20T20:03:56.247799Z",
     "shell.execute_reply": "2024-09-20T20:03:56.247316Z",
     "shell.execute_reply.started": "2024-09-20T20:03:55.224651Z"
    }
   },
   "outputs": [],
   "source": [
    "vmin_res = -np.max(np.abs(plot_residual))\n",
    "vmax_res = np.max(np.abs(plot_residual))\n",
    "pred_bias = spatial_bias(plot_output, plot_target)\n",
    "pred_rmse = spatial_rmse(plot_output, plot_target)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1,ncols=2,\n",
    "                        figsize=(15,4))\n",
    "\n",
    "title = 'Residuals - RMSE: {:.2f} K, bias: {:.2f} K'.format(pred_rmse, pred_bias)\n",
    "im_res = plot_spatial(plot_residual, axs[0], title,  **plot_val_kwargs.get('plot_residual_kwargs'))\n",
    "cbar = plt.colorbar(im_res, ax=axs[0], orientation='vertical', label=f'{var_name} [K]')\n",
    "\n",
    "plot_power_spectrum(plot_input, axs[1])\n",
    "plot_power_spectrum(plot_target, axs[1])\n",
    "plot_power_spectrum(plot_output, axs[1])\n",
    "axs[1].legend(['input', 'ground-truth', 'Prithvi WxC'])\n",
    "axs[1].set_title(f'Power spectrum of {var_name_title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5388044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
