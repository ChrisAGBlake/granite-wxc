data:
  type: ecmwf
  # data_dir: /Volumes/ChrisHD/granite-wxc/ecmwf
  data_dir: /media/chris/ChrisHD/granite-wxc/ecmwf
  # parsed_data_dir: /Volumes/ChrisHD/granite-wxc/ecmwf-parsed
  parsed_data_dir: /media/chris/ChrisHD/granite-wxc/ecmwf-parsed
  # parsed_data_dir: ecmwf-parsed
  input_surface_vars:
    - t2m
    - u10
    - v10
    - msl
  input_vertical_vars:
    - t
    - u
    - v
    - w
    - q
    - gh
  aifs_surface_vars:
    - skt
    - u10
    - v10
    - msl
  aifs_vertical_vars:
    - t
    - u
    - v
    - w
    - q
    - z
  input_static_surface_vars: 
    - lsm
    - z
  input_levels:  [200, 400, 600, 850, 925, 1000] 
  output_vars:
    - t2m
    - u10
    - v10
    - msl
  n_input_timestamps: 1
  downscale_factor: 2
  # lat_range: [-80, 80]
  # lon_range: [0, 360]
  # input_size_lat: 400 
  # input_size_lon: 900 
  # lat_range: [-10, 10]
  # lon_range: [0, 20]
  input_size_lat: 100 
  input_size_lon: 100 
  window_sz: 20

model:

  # Platform independent config
  num_static_channels: 6 
  embed_dim: 1200 # 2560 
  token_size:
    - 1
    - 1
  n_blocks_encoder: 8 # 12 
  mlp_multiplier: 4
  n_heads: 12 # 16 
  dropout_rate: 0.0
  drop_path: 0.05
  
  # Accepted values: temporal, climate, none
  residual: temporal
  
  residual_connection: True
  encoder_shift: False

  downscaling_patch_size: [2, 2]
  downscaling_embed_dim: 256
  encoder_decoder_type: 'conv' # ['conv', 'transformer']
  encoder_decoder_upsampling_mode: pixel_shuffle # ['nearest', 'bilinear', 'pixel_shuffle', 'conv_transpose']
  encoder_decoder_kernel_size_per_stage: [[3], [3]] # Optional, default = 3 for conv_tanspose [[3], [2]]
  encoder_decoder_scale_per_stage: [[1], [2]] # First list determines before/after backbone
  encoder_decoder_conv_channels: 128

# aws config
aws:
  bucket: 'granite-wxc'
  profile_name: null
  parsed_data_dir: 'ecmwf-parsed'

# training config
train:
  batch_size: 1
  num_epochs: 400
  dl_num_workers: 2
  train_split: 0.95
  lr: 0.00001
  grad_accum_steps: 8

# old training config
# TODO update code to use new config structure
job_id: inference-test
batch_size: 1
num_epochs: 400
dl_num_workers: 2
dl_prefetch_size: 1
learning_rate: 0.0001
limit_steps_train: 250
limit_steps_valid: 25
min_lr: 0.00001
max_lr: 0.0002
warm_up_steps: 0
mask_unit_size:
  - 10 # 15
  - 10 # 16
mask_ratio_inputs: 0.0
mask_ratio_targets: 0.0
max_batch_size: 16

path_experiment: experiment

backbone_freeze: True
backbone_prefix: encoder.
finetune_w_static: True
strict_matching: true
